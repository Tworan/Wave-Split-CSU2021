{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from asteroid.models import BaseModel\n",
    "import soundfile as sf\n",
    "import time\n",
    "from pystoi import stoi\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 计算STOI"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "mixture_dir = '/home/oneran/Data/Libri2Mix/wav16k/both/dev/mix_both'\n",
    "s1 = '/home/oneran/Data/Libri2Mix/wav16k/both/dev/s1'\n",
    "s2 = '/home/oneran/Data/Libri2Mix/wav16k/both/dev/s2'\n",
    "##################################################################\n",
    "import torch\n",
    "from asteroid.models import ConvTasNet\n",
    "from asteroid.engine.system import System\n",
    "from asteroid.engine.optimizers import make_optimizer\n",
    "from asteroid.losses import PITLossWrapper, pairwise_neg_sisdr\n",
    "import threading\n",
    "import time\n",
    "# torch.set_default_dtype(torch.float16)\n",
    "checkpoint = torch.load('/home/oneran/Downloads/16k_ep7.ckpt', map_location=torch.device('cpu'))\n",
    "model = ConvTasNet(2, mask_act='relu', norm_type='gLN', kernel_size=32, stride=16)\n",
    "model.sample_rate = 16000\n",
    "model.eval()\n",
    "temp = checkpoint['state_dict']\n",
    "loss_func = PITLossWrapper(pairwise_neg_sisdr, pit_from=\"pw_mtx\")\n",
    "optimizer = make_optimizer(model.parameters())\n",
    "system = System(model, optimizer, loss_func, None)\n",
    "system.load_state_dict(temp)\n",
    "system.cpu()\n",
    "to_save = system.model.serialize()\n",
    "model.load_state_dict(to_save['state_dict'])\n",
    "model.cuda()\n",
    "##################################################################\n",
    "model.sample_rate = 16000\n",
    "histroys = []\n",
    "print('load')\n",
    "\n",
    "# def f(x, y):\n",
    "#     if len(x) > len(y):\n",
    "#         return x[:-(len(x) - len(y))]\n",
    "#     else:\n",
    "#         return np.pad(x, ((0, len(y.flatten()) - len(x.flatten()))), mode='constant', constant_values=0)\n",
    "def read_audio(mixture, s1_path, s2_path, rec):\n",
    "    # time_1 = time.time()\n",
    "    wav1, _ = sf.read(s1_path)\n",
    "    wav2, _ = sf.read(s2_path)\n",
    "    wavmix, _ = sf.read(mixture)\n",
    "    rec.append([wav1, wav2, wavmix])\n",
    "    # time_2 = time.time()\n",
    "    # print(time_2 - time_1)\n",
    "\n",
    "def process(wav, rec):\n",
    "    # time_1 = time.time()\n",
    "    sep = model.separate(wav)\n",
    "    rec.append(sep)\n",
    "    # time_2 = time.time()\n",
    "    # print(time_2 - time_1)\n",
    "\n",
    "def cal_stoi(sep, wav1, wav2, histroys):\n",
    "    sep1, sep2 = sep[0, 0], sep[0, 1]\n",
    "    # sep1, sep2 = f(librosa.resample(sep1, 8000, 16000), wav1), f(librosa.resample(sep2, 8000, 16000), wav2)\n",
    "    stoi_1_1, stoi_1_2 = stoi(wav1, sep1, 16000), stoi(wav2, sep2, 16000)\n",
    "    stoi_2_1, stoi_2_2 = stoi(wav2, sep1, 16000), stoi(wav1, sep2, 16000)\n",
    "    stoi_mean_1, stoi_mean_2 = sum([stoi_1_1, stoi_1_2]), sum([stoi_2_1, stoi_2_2])\n",
    "    histroys.append([stoi_1_1, stoi_1_2] if stoi_mean_1 > stoi_mean_2 else [stoi_2_1, stoi_2_2]) \n",
    "\n",
    "audios = []\n",
    "seps = []\n",
    "stoi_threads_pool = []\n",
    "for i, file in enumerate(os.listdir(mixture_dir)):\n",
    "    mixture = mixture_dir + '/' + file\n",
    "    s1_path = s1 + '/' + file\n",
    "    s2_path = s2 + '/' + file\n",
    "    #* 开始处理上一条\n",
    "    if i != 0:\n",
    "        t.join()\n",
    "        audio = audios.pop()\n",
    "        wavmix = audio[-1]\n",
    "        wavmix = np.expand_dims(wavmix, axis=0).astype(np.float32)\n",
    "        sep_t = threading.Thread(target=process, kwargs={'wav': wavmix, 'rec': seps})\n",
    "        sep_t.start()\n",
    "\n",
    "    #* 加载下一条\n",
    "\n",
    "    t = threading.Thread(target=read_audio, kwargs={'mixture': mixture, 's1_path': s1_path, 's2_path': s2_path, 'rec': audios})\n",
    "    t.start()\n",
    "\n",
    "    if i != 0:\n",
    "        sep_t.join()\n",
    "        sep = seps.pop()\n",
    "        wav1, wav2 = audio[0], audio[1]\n",
    "\n",
    "    # wavmix = librosa.resample(wavmix, 16000, 8000)\n",
    "    \n",
    "    if i != 0:\n",
    "        t_stoi = threading.Thread(target=cal_stoi, kwargs={'sep': sep, 'wav1': wav1, 'wav2': wav2, 'histroys': histroys})\n",
    "        t_stoi.start()\n",
    "        stoi_threads_pool.append(t_stoi)\n",
    "        if len(stoi_threads_pool) >= 20:\n",
    "            for _t in stoi_threads_pool:\n",
    "                _t.join()\n",
    "            stoi_threads_pool = []\n",
    "\n",
    "        # historys.append([stoi_1_1, stoi_1_2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/oneran/.local/lib/python3.10/site-packages/asteroid/models/base_models.py:55: UserWarning: Other sub-components of the model might have a `sample_rate` attribute, be sure to modify them for consistency.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "load\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 测试silentspeaker"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import torch\n",
    "from asteroid.models import ConvTasNet\n",
    "from asteroid.engine.system import System\n",
    "from asteroid.engine.optimizers import make_optimizer\n",
    "from asteroid.losses import PITLossWrapper, pairwise_neg_sisdr\n",
    "# torch.set_default_dtype(torch.float16)\n",
    "checkpoint = torch.load('/home/oneran/Downloads/16k_ep7.ckpt', map_location=torch.device('cpu'))\n",
    "model = ConvTasNet(2, mask_act='relu', norm_type='gLN', kernel_size=32, stride=16)\n",
    "model.sample_rate = 16000\n",
    "model.eval()\n",
    "temp = checkpoint['state_dict']\n",
    "loss_func = PITLossWrapper(pairwise_neg_sisdr, pit_from=\"pw_mtx\")\n",
    "optimizer = make_optimizer(model.parameters())\n",
    "system = System(model, optimizer, loss_func, None)\n",
    "system.load_state_dict(temp)\n",
    "system.cpu()\n",
    "to_save = system.model.serialize()\n",
    "model.load_state_dict(to_save['state_dict'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "model.cuda()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ConvTasNet(\n",
       "  (encoder): Encoder(\n",
       "    (filterbank): FreeFB()\n",
       "  )\n",
       "  (masker): TDConvNet(\n",
       "    (bottleneck): Sequential(\n",
       "      (0): GlobLN()\n",
       "      (1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (TCN): ModuleList(\n",
       "      (0): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (1): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (2): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (3): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (4): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (5): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (6): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (7): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (8): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (9): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (10): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (11): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (12): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (13): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (14): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (15): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (16): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (17): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (18): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (19): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (20): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (21): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (22): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (23): Conv1DBlock(\n",
       "        (shared_block): Sequential(\n",
       "          (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): GlobLN()\n",
       "          (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,), groups=512)\n",
       "          (4): PReLU(num_parameters=1)\n",
       "          (5): GlobLN()\n",
       "        )\n",
       "        (res_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (skip_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (mask_net): Sequential(\n",
       "      (0): PReLU(num_parameters=1)\n",
       "      (1): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (output_act): ReLU()\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (filterbank): FreeFB()\n",
       "  )\n",
       "  (enc_activation): Identity()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "import soundfile as sf\n",
    "import numpy as np\n",
    "mixture_dir = '/home/oneran/Data/Libri2Mix/wav16k/both/test/'\n",
    "def energy_level(wav):\n",
    "    phase_over_wav = wav[np.where(np.abs(wav) >= 0.1)]\n",
    "    return 10 * np.log10(np.sum(phase_over_wav ** 2) / len(wav) * 16000 + 1e-5)\n",
    "\n",
    "s1_history = []\n",
    "s2_history = []\n",
    "for file in os.listdir(mixture_dir + '/mix_both'):\n",
    "    # if len(file.split('_')) < 3:\n",
    "    #     continue\n",
    "    mixture = mixture_dir + '/mix_both/' + file\n",
    "    wavmix, _ = sf.read(mixture)\n",
    "    # wavmix = librosa.resample(wavmix, 16000, 8000)\n",
    "    wavmix = np.expand_dims(wavmix, axis=0).astype(np.float32)\n",
    "    # wavmix = torch.Tensor(mixture, device='cuda')\n",
    "    sep = model.separate(wavmix)\n",
    "    s1_history.append(energy_level(sep[0, 0]))\n",
    "    s2_history.append(energy_level(sep[0, 1]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "counter = 0\n",
    "pos = 0\n",
    "threshold = 20\n",
    "for i, s1, s2 in zip(range(len(s1_history)), s1_history, s2_history):\n",
    "    counter += 1\n",
    "    if s1 - s2 >= threshold: \n",
    "    # if s1 <= 0 or s2 <= 0:\n",
    "        pos += 1\n",
    "            \n",
    "print(counter, pos)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6000 2741\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "audios = []\n",
    "for file in os.listdir(mixture_dir + '/mix_both'):\n",
    "    # if len(file.split('_')) < 3:\n",
    "    #     continue\n",
    "    mixture = mixture_dir + '/mix_both/' + file\n",
    "    audios.append(mixture)\n",
    "index = np.where(np.abs(np.array(s1_history) - np.array(s2_history)) >= threshold) \n",
    "# index = np.where((np.array(s1_history) <= 5) + (np.array(s2_history) <= 5))\n",
    "_audios = np.array(audios)\n",
    "len([elem for elem in (set(_audios.tolist()) - set(_audios[index].tolist())) if len(elem.split('_')) >= 4]) + len([elem for elem in _audios[index] if len(elem.split('_')) <= 3])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "[elem for elem in (set(_audios.tolist()) - set(_audios[index].tolist())) if len(elem.split('_')) >= 4]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['/home/oneran/Data/Libri2Mix/wav16k/both/test//mix_both/4970-29093-0019_121-121726-0000_single.wav',\n",
       " '/home/oneran/Data/Libri2Mix/wav16k/both/test//mix_both/5142-36377-0013_3729-6852-0040_single.wav',\n",
       " '/home/oneran/Data/Libri2Mix/wav16k/both/test//mix_both/5683-32879-0004_5105-28240-0022_single.wav',\n",
       " '/home/oneran/Data/Libri2Mix/wav16k/both/test//mix_both/7127-75946-0003_3729-6852-0022_single.wav',\n",
       " '/home/oneran/Data/Libri2Mix/wav16k/both/test//mix_both/3729-6852-0013_237-134500-0002_single.wav',\n",
       " '/home/oneran/Data/Libri2Mix/wav16k/both/test//mix_both/5683-32879-0009_2961-960-0018_single.wav',\n",
       " '/home/oneran/Data/Libri2Mix/wav16k/both/test//mix_both/121-121726-0011_237-126133-0017_single.wav',\n",
       " '/home/oneran/Data/Libri2Mix/wav16k/both/test//mix_both/5142-36377-0009_1284-1180-0007_single.wav',\n",
       " '/home/oneran/Data/Libri2Mix/wav16k/both/test//mix_both/7127-75947-0024_1089-134686-0026_single.wav',\n",
       " '/home/oneran/Data/Libri2Mix/wav16k/both/test//mix_both/1580-141084-0010_3570-5696-0002_single.wav',\n",
       " '/home/oneran/Data/Libri2Mix/wav16k/both/test//mix_both/672-122797-0048_61-70968-0020_single.wav',\n",
       " '/home/oneran/Data/Libri2Mix/wav16k/both/test//mix_both/7127-75946-0004_2961-960-0013_single.wav',\n",
       " '/home/oneran/Data/Libri2Mix/wav16k/both/test//mix_both/1089-134691-0020_7021-85628-0000_single.wav',\n",
       " '/home/oneran/Data/Libri2Mix/wav16k/both/test//mix_both/5142-36377-0013_8455-210777-0009_single.wav',\n",
       " '/home/oneran/Data/Libri2Mix/wav16k/both/test//mix_both/5683-32866-0016_8555-284449-0019_single.wav',\n",
       " '/home/oneran/Data/Libri2Mix/wav16k/both/test//mix_both/5142-36377-0010_5105-28241-0003_single.wav',\n",
       " '/home/oneran/Data/Libri2Mix/wav16k/both/test//mix_both/2961-961-0020_5142-33396-0003_single.wav',\n",
       " '/home/oneran/Data/Libri2Mix/wav16k/both/test//mix_both/672-122797-0031_908-31957-0013_single.wav',\n",
       " '/home/oneran/Data/Libri2Mix/wav16k/both/test//mix_both/4446-2273-0033_5683-32866-0020_single.wav']"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "def process(wavpath, savepath):\n",
    "    mix, _ = sf.read(wavpath)\n",
    "    mix = np.expand_dims(mix, 0).astype(np.float32)\n",
    "    mix = np.expand_dims(mix, 0).astype(np.float32)\n",
    "    seps = model.separate(mix)\n",
    "    sf.write(savepath + 'mix_est1.wav', seps[0, 0], 16000)\n",
    "    sf.write(savepath + 'mix_est2.wav', seps[0, 1], 16000)\n",
    "    print(energy_level(seps[0, 0]), energy_level(seps[0, 1]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "fpath = '/home/oneran/Data/Libri2Mix/wav16k/both/test//mix_both/8463-294825-0019_5639-40744-0038_single.wav'\n",
    "savepath = '/home/oneran/Desktop/'\n",
    "process(fpath, savepath)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7.470005422202341 11.921510744746058\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.10.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.2 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}